---
theme: default
class:
  - invert
marp: true
---
# (De)optimising JavaScript

![JS LOGO](https://iconape.com/wp-content/files/vr/353405/svg/javascript-js-seeklogo.com.svg)

---

## Goal :

To make things faster, we need to understand, what slows things down, 

> question we want to understand today _why does doing something like X slow things down_

And then, we will argue with proof (because we are all engineers and we <3 maths) the claims and assumptions we make.


`Visualising Javascript Execution > Phases of execution`

---

## Parsing :

- The first step of any execution is parsing. So all JS has to be parsed.
- Parsing is slow. 1 Mb of JS can take as much as 1 second to be parsed.
- So to make things faster : parse as less as possible, but thats easier said than done !

---

At the heart of all parsing is the V8, 

Parsing happens in two phases :
> **Eager**  
all of the code is parsed all at once.

> **Lazy**  
Do the bare minimum and do it later.

---

## Unfortunately,
you cannot control it !!

---

Okay, lets understand what we just said !

```js
const a = 1;
const b = 2;
function addTwoNumbers(a,b){
	return a+b;
}
addTwoNumbers(a,b)
```

---

## Lets rewind and take a look at the bigger picture:

![image](https://user-images.githubusercontent.com/49792104/125257317-ee346c80-e31a-11eb-8d76-9426185ce1e4.png)


---

The first thing that executes on a web page is actually an html parser, not the JS.
When the html parser encounters the script tag, it fetches the js from the CDN.

What is sent back is a stream of bytes, which is viewed as a file

And now the fun part starts! 

---

This series of bytes is `decoded`

And decoding actually looks like this:

```js
 f  u  n  c  t  i  o  n
 66 75 6e 63 74 69  ....
```

---

The first things that a parser does is
generates an abstract syntax tree which looks somewhat like this:

https://astexplorer.net/

```js
const a = 1;
const b = 2;
function addTwoNumbers(a,b){
	return a+b;
}
addTwoNumbers(a,b)
```
---

While the parser is creating this .... it checks for "Syntax errros"

---

# Ignition time

The v8 engine contains an interpreter which is popularly known as the ignition interpreter.

![image](https://user-images.githubusercontent.com/49792104/125308011-302ad600-e34e-11eb-8890-02c0bbdc765a.png)

---

# The ignition interpreter
generates the bytecode from the ast that got created by the parser.
![image](https://user-images.githubusercontent.com/49792104/125308558-a16a8900-e34e-11eb-8e2b-212407ef3166.png)


--- 

# @PlayTime :: Show me some bytecode 

`cd HandsOn`
`node --print-bytecode showByteCode.js > bytecode`

---

# Lets filter down 

`node --print-bytecode --print-bytecode-filter=calc showByteCode.js`

---

# Bytecode !!

```
❯ node --print-bytecode --print-bytecode-filter=calc showByteCode.js    
[generated bytecode for function: calc (0x1c7ed1dd5911 <SharedFunctionInfo calc>)]
Parameter count 2
Register count 2
Frame size 16
   48 S> 0x1c7ed1dd5b56 @    0 : 28 02 00 01       LdaNamedProperty a0, [0], [1]
   42 E> 0x1c7ed1dd5b5a @    4 : 42 32 00          MulSmi [50], [0]
         0x1c7ed1dd5b5d @    7 : 26 fb             Star r0
   74 S> 0x1c7ed1dd5b5f @    9 : 28 02 00 01       LdaNamedProperty a0, [0], [1]
   68 E> 0x1c7ed1dd5b63 @   13 : 34 fb 03          Add r0, [3]
         0x1c7ed1dd5b66 @   16 : 26 fa             Star r1
   82 E> 0x1c7ed1dd5b68 @   18 : 28 02 01 04       LdaNamedProperty a0, [1], [4]
   76 E> 0x1c7ed1dd5b6c @   22 : 34 fa 06          Add r1, [6]
   84 S> 0x1c7ed1dd5b6f @   25 : aa                Return 
Constant pool (size = 2)
0x1c7ed1dd5b01: [FixedArray] in OldSpace
 - map: 0x1c7ec2480729 <Map>
 - length: 2
           0: 0x1c7ef5a3adf1 <String[#1]: x>
           1: 0x1c7eb203b3f9 <String[#1]: y>
Handler Table (size = 0)
Source Position Table (size = 18)
0x1c7ed1dd5b71 <ByteArray[18]>
```
---

# Lets read the bytecode 

> Ignition uses `registers` to execute the byteode r0 and r1, but there is also another one called `a0` register

Registers: Holds values or variables.
`         0x1c7ed1dd5b5d @    7 : 26 fb             Star r0`

Accumulators : 
used for input / output or maybe both 

---
# a0 : used for values that got passed to a function
`   48 S> 0x1c7ed1dd5b56 @    0 : 28 02 00 01       LdaNamedProperty a0, [0], [1]`

Here we passed an object :
```
calc({
    x: 10,
    y: 20,
    z: 30
})
```
So now a `Shape table` gets created.
Shape table contains info on where to find properties on the object (oversimplified)

---

# What does it mean ?

`   48 S> 0x1c7ed1dd5b56 @    0 : 28 02 00 01       LdaNamedProperty a0, [0], [1]`
In the shape table a0, we are using a property called `x` and that can be found in index 0

```
0x1c7ed1dd5b01: [FixedArray] in OldSpace
 - map: 0x1c7ec2480729 <Map>
 - length: 2
           0: 0x1c7ef5a3adf1 <String[#1]: x> ******
           1: 0x1c7eb203b3f9 <String[#1]: y>
```
Similarly for `y` at index 1
`  82 E> 0x1c7ed1dd5b68 @   18 : 28 02 01 04       LdaNamedProperty a0, [1], [4]`

---

# wait, what about z ?

Since we are not using it anywhere, we are not going to keep it in the shape table !
but if you do use it, the ignition interpreter will include it.

---

# now all at once, you are the ingnition interpreter

```js
    const value = 50 * obj.x;
    return value + obj.x + obj.y;
```

```
   48 S> 0x1c7ed1dd5b56 @    0 : 28 02 00 01       LdaNamedProperty a0, [0], [1]
   // get the value of x from the index
   42 E> 0x1c7ed1dd5b5a @    4 : 42 32 00          MulSmi [50], [0]
   // mutiply by 50 !
         0x1c7ed1dd5b5d @    7 : 26 fb             Star r0
   // store in r0
   ------------------------------------------
   74 S> 0x1c7ed1dd5b5f @    9 : 28 02 00 01       LdaNamedProperty a0, [0], [1]
   // get the value of x from the index
   68 E> 0x1c7ed1dd5b63 @   13 : 34 fb 03          Add r0, [3]
   // Add r0 with the value fetched
         0x1c7ed1dd5b66 @   16 : 26 fa             Star r1
   // store temporarily in r1       
   82 E> 0x1c7ed1dd5b68 @   18 : 28 02 01 04       LdaNamedProperty a0, [1], [4]
   // get value of y
   76 E> 0x1c7ed1dd5b6c @   22 : 34 fa 06          Add r1, [6]
   // add them to r1
   84 S> 0x1c7ed1dd5b6f @   25 : aa                Return 
``` 
---

# We just read bytecode !!

![gif](https://media3.giphy.com/media/eLeH1WR7rbfwFMWBzO/200w.webp?cid=ecf05e47gyawffe4fcz03hz2ismsulqfqaa9kcnd6rn20rkz&rid=200w.webp&ct=g)

---

# Wait where is the optimisation !

there are few things that i Skipped in the bytecode
```
   48 S> 0x1c7ed1dd5b56 @    0 : 28 02 00 01       LdaNamedProperty a0, [0], [1]**
   42 E> 0x1c7ed1dd5b5a @    4 : 42 32 00          MulSmi [50], [0]**
         0x1c7ed1dd5b5d @    7 : 26 fb             Star r0
   74 S> 0x1c7ed1dd5b5f @    9 : 28 02 00 01       LdaNamedProperty a0, [0], [1]**
   68 E> 0x1c7ed1dd5b63 @   13 : 34 fb 03          Add r0, [3]**
         0x1c7ed1dd5b66 @   16 : 26 fa             Star r1
   82 E> 0x1c7ed1dd5b68 @   18 : 28 02 01 04       LdaNamedProperty a0, [1], [4]**
   76 E> 0x1c7ed1dd5b6c @   22 : 34 fa 06          Add r1, [6]**
   84 S> 0x1c7ed1dd5b6f @   25 : aa                Return 
```
---

# Shape table

When you pass in an object in v8, it creates a **Shape table**
Also known a `hidden class` > but lets forget all of that.
It contains the offsets on the property as where u can find them
Note that there are mutiple properties on an object that you do not access. so they may not neccessarily correspond to index 

`offset !== index`

---

![image](https://user-images.githubusercontent.com/49792104/125319356-5190bf80-e358-11eb-9f73-3b904f6cba8c.png)

---

# Inline caching 

Inline cahing is a technique used to store the values of previous operations into the data structure and that is used everytime a common repeatable operations is encountered.
e.g a property 

![image](https://user-images.githubusercontent.com/49792104/125409149-3e720400-e3d9-11eb-981e-dfe0f782da80.png)


---

# Moving towards the turbofan optimiser

This iniline cache not only does the work of optimising the interpreter
but also generates something called a feedback

![image](https://user-images.githubusercontent.com/49792104/125409404-7e38eb80-e3d9-11eb-8444-ef9f3fb16610.png)

---

# Going back to what we skipped 

```
   48 S> 0x1c7ed1dd5b56 @    0 : 28 02 00 01       LdaNamedProperty a0, [0], [1]**
   42 E> 0x1c7ed1dd5b5a @    4 : 42 32 00          MulSmi [50], [0]**
         0x1c7ed1dd5b5d @    7 : 26 fb             Star r0
   74 S> 0x1c7ed1dd5b5f @    9 : 28 02 00 01       LdaNamedProperty a0, [0], [1]**
   68 E> 0x1c7ed1dd5b63 @   13 : 34 fb 03          Add r0, [3]**
         0x1c7ed1dd5b66 @   16 : 26 fa             Star r1
   82 E> 0x1c7ed1dd5b68 @   18 : 28 02 01 04       LdaNamedProperty a0, [1], [4]**
   76 E> 0x1c7ed1dd5b6c @   22 : 34 fa 06          Add r1, [6]**
   84 S> 0x1c7ed1dd5b6f @   25 : aa                Return 
```

These are actually references to a `Feedback Vector Slot`

---

# Hot and cold functions

When a particular function gets invoked multiple times.
This fucntion is considered "HOT"

## Enter turbofan compiler

---

# Turbofan

Turbofan now picks up the `generated bytecode` + `Feedback Vector Slot` 
To generate a higly optimised machine code that is unique to the architecture.

This code needs no in between steps, these runs directly on your machine.

---

# @play time 

`node example-1.js`

```
❯ node example-1.js 
7.097876
```

wait ..... how do I know if it was turbofanned

---

# Add the flag and run again

```
❯ node --trace-opt example-1.js 
[marking 0x1df56995d109 <JSFunction (sfi = 0x1df51fb45759)> for optimized recompilation, reason: hot and stable]
[marking 0x1df569962151 <JSFunction add (sfi = 0x1df51fb45871)> for optimized recompilation, reason: small function]
[compiling method 0x1df569962151 <JSFunction add (sfi = 0x1df51fb45871)> using TurboFan]
[compiling method 0x1df56995d109 <JSFunction (sfi = 0x1df51fb45759)> using TurboFan OSR]
[optimizing 0x1df56995d109 <JSFunction (sfi = 0x1df51fb45759)> - took 0.179, 0.580, 0.016 ms]
[optimizing 0x1df569962151 <JSFunction add (sfi = 0x1df51fb45871)> - took 0.446, 0.687, 0.011 ms]
[completed optimizing 0x1df569962151 <JSFunction add (sfi = 0x1df51fb45871)>]
9.839967
```

`[compiling method 0x1df569962151 <JSFunction add (sfi = 0x1df51fb45871)> using TurboFan]`

### But why go to turbofan 
```
[marking 0x1df56995d109 <JSFunction (sfi = 0x1df51fb45759)> for optimized recompilation, reason: hot and stable]
[marking 0x1df569962151 <JSFunction add (sfi = 0x1df51fb45871)> for optimized recompilation, reason: small function]
```
---


# (DE)Optimsie this  !!


![](https://media0.giphy.com/media/3oEduY5Jdl8DUbV0hW/200w.webp?cid=ecf05e47wmddbkzkwoz7o1pzc00p3qu4at2blh8w3wrikhoq&rid=200w.webp&ct=g)

---

# try running example 2


Do note the `add(2,"4");` on line 18

```
❯ node --trace-opt example-2.js | grep add 
[marking 0x133ff57a5c49 <JSFunction add (sfi = 0x133f096c8741)> for optimized recompilation, reason: small function]
[compiling method 0x133ff57a5c49 <JSFunction add (sfi = 0x133f096c8741)> using TurboFan]
[optimizing 0x133ff57a5c49 <JSFunction add (sfi = 0x133f096c8741)> - took 0.359, 0.638, 0.007 ms]
[completed optimizing 0x133ff57a5c49 <JSFunction add (sfi = 0x133f096c8741)>]
```
Nothing happened .... still optimised.

---

# run again with the --trace-deopt flag

```
❯ node --trace-opt --trace-deopt example-2.js | grep add
[marking 0x07c0b7ae6509 <JSFunction add (sfi = 0x7c0234a4151)> for optimized recompilation, reason: small function]
[compiling method 0x07c0b7ae6509 <JSFunction add (sfi = 0x7c0234a4151)> using TurboFan]
[optimizing 0x07c0b7ae6509 <JSFunction add (sfi = 0x7c0234a4151)> - took 0.403, 0.576, 0.010 ms]
[completed optimizing 0x07c0b7ae6509 <JSFunction add (sfi = 0x7c0234a4151)>]
     11: 0x07c0b7ae6509 ; rdx 0x07c0b7ae6509 <JSFunction add (sfi = 0x7c0234a4151)>
    0x7ffeefbfe570: [top +  56] <- 0x07c0b7ae6509 <JSFunction add (sfi = 0x7c0234a4151)> ;  stack parameter (input #11)
[deoptimizing (DEOPT eager): begin 0x07c0b7ae6509 <JSFunction add (sfi = 0x7c0234a4151)> (opt #0) @1, FP to SP delta: 24, caller sp: 0x7ffeefbfe540]
  reading input frame add => bytecode_offset=2, args=3, height=0, retval=0(#0); inputs:
      0: 0x07c0b7ae6509 ;  [fp -  16]  0x07c0b7ae6509 <JSFunction add (sfi = 0x7c0234a4151)>
  translating interpreted frame add => bytecode_offset=2, variable_frame_size=8, frame_size=80
    0x7ffeefbfe508: [top +  24] <- 0x07c0b7ae6509 <JSFunction add (sfi = 0x7c0234a4151)> ;  function (input #0)
[deoptimizing (eager): end 0x07c0b7ae6509 <JSFunction add (sfi = 0x7c0234a4151)> @1 => node=2, pc=0x000100a0b280, caller sp=0x7ffeefbfe540, took 0.346 ms]
```
---

# Wait what about the other one, where I do not add strings

```
~/codebase/personal/deoptimise-js/HandsOn main*
❯ node --trace-opt --trace-deopt example-1.js | grep add
[marking 0x3bad1e22ca11 <JSFunction add (sfi = 0x3badcf2e4129)> for optimized recompilation, reason: small function]
[compiling method 0x3bad1e22ca11 <JSFunction add (sfi = 0x3badcf2e4129)> using TurboFan]
[optimizing 0x3bad1e22ca11 <JSFunction add (sfi = 0x3badcf2e4129)> - took 0.373, 0.647, 0.008 ms]
[completed optimizing 0x3bad1e22ca11 <JSFunction add (sfi = 0x3badcf2e4129)>]
```
---
# Internally

Since the structure keeps changing... the Shape Object keeps getting recreated every single time.

So now the lookup becomes a Linear Search which is O(n) and youhave slowness

---
# Congratulations you have successfully deoptimised your code !!
# Mission accomplished 

## And this time you have proof too ... to show in your appraisal !
---


# This is where Typescript comes in and plays a major role
![ts](https://www.typescriptlang.org/images/branding/logo-grouping.svg)

---

# Mumbo Jumbo .... is my code actually slow ?

```
❯ node example-3.js
14.533002

~/codebase/personal/deoptimise-js/HandsOn main*
❯ node example-3.js
14.601682
```

By just adding `add(2,"4");` in `example-4.js`

```
~/codebase/personal/deoptimise-js/HandsOn main*
❯ node example-4.js
39.978347

~/codebase/personal/deoptimise-js/HandsOn main*
❯ node example-4.js
39.938796
````
---

# So now we have actual proof that we slowed execution time by 3X
---

# I want to keep things deoptimised.

- Add flags to the compiler 
`%NeverOptimizeFunction(add)`

- Run allowing native syntax
`node --allow-natives-syntax example-5.js`

```shell
~/codebase/personal/deoptimise-js/HandsOn main*
❯  node --allow-natives-syntax example-5.js 
317.228401
```

---

# taking control of the optimiser .. can I ?

```
const add = (a,b) => a+b;
%OptimizeFunctionOnNextCall(add);
add(2,5)
```
```
❯  node --allow-natives-syntax --trace-opt example-6.js
[manually marking 0x3674eb71def1 <JSFunction add (sfi = 0x367428f07979)> for non-concurrent optimization]
[compiling method 0x3674eb71def1 <JSFunction add (sfi = 0x367428f07979)> using TurboFan]
[optimizing 0x3674eb71def1 <JSFunction add (sfi = 0x367428f07979)> - took 8.810, 13.365, 0.059 ms]
```
`[manually marking 0x3674eb71def1 <JSFunction add (sfi = 0x367428f07979)> for non-concurrent optimization]`

---

# Does fucntion inlining matter? if not ... why ?
 
 ```js
const double = (x) => x + x;
const sumOfDoubles = (y,z) => double(y) + double(z)
const y = 1;
const z = 4;
performance.mark("starting loop")
while (iterations--) {
  sumOfDoubles(y,z);
}
```

---

# If i replace 
```
const double = (x) => x + x;
const sumOfDoubles = (y,z) => double(y) + double(z)
```
with 
```
const sumOfDoubles = (y,z) => y+y + z+z
```
the execution time reamins fairly constant

---

```
❯ node --trace-turbo-inlining function-inlining.js 
Considering 0x107825780 {0x199dca709681 <SharedFunctionInfo double>} for inlining with 0x107825a90 {0x199dca712911 <FeedbackVector[1]>}
Inlining small function(s) at call site #27:JSCall
Inlining 0x107825780 {0x199dca709681 <SharedFunctionInfo double>} into 0x107812a78 {0x199dca7096d1 <SharedFunctionInfo sumOfDoubles>}
Considering 0x107825780 {0x199dca709681 <SharedFunctionInfo double>} for inlining with 0x107825a90 {0x199dca712911 <FeedbackVector[1]>}
Inlining small function(s) at call site #41:JSCall
Inlining 0x107825780 {0x199dca709681 <SharedFunctionInfo double>} into 0x107812a78 {0x199dca7096d1 <SharedFunctionInfo sumOfDoubles>}
Considering 0x107815050 {0x199dca7096d1 <SharedFunctionInfo sumOfDoubles>} for inlining with 0x107815060 {0x199dca7127b9 <FeedbackVector[5]>}
1 candidate(s) for inlining:
- candidate: JSCall node #51 with frequency 26813, 1 target(s):
  - target: 0x107815050 {0x199dca7096d1 <SharedFunctionInfo sumOfDoubles>}, bytecode size: 26, existing opt code's inlined bytecode size: 12
Inlining 0x107815050 {0x199dca7096d1 <SharedFunctionInfo sumOfDoubles>} into 0x107818e90 {0x199dca709569 <SharedFunctionInfo>}
Considering 0x107816b78 {0x199dca709681 <SharedFunctionInfo double>} for inlining with 0x107816b88 {0x199dca712911 <FeedbackVector[1]>}
Inlining small function(s) at call site #91:JSCall
Inlining 0x107816b78 {0x199dca709681 <SharedFunctionInfo double>} into 0x107818e90 {0x199dca709569 <SharedFunctionInfo>}
Considering 0x107816b78 {0x199dca709681 <SharedFunctionInfo double>} for inlining with 0x107816b88 {0x199dca712911 <FeedbackVector[1]>}
Inlining small function(s) at call site #105:JSCall
Inlining 0x107816b78 {0x199dca709681 <SharedFunctionInfo double>} into 0x107818e90 {0x199dca709569 <SharedFunctionInfo>}
11.311391
```

---
# Feel like a superhero now ?

---